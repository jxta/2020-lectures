{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf321e6-4195-11ea-86a9-02420a01000c",
     "next": "9bf322f4-4195-11ea-86a9-02420a01000c",
     "previous": null
    }
   },
   "source": [
    "# 11 総合演習問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf322f4-4195-11ea-86a9-02420a01000c",
     "next": "9bf323c6-4195-11ea-86a9-02420a01000c",
     "previous": "9bf321e6-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "いよいよ最後の章になりました。この章では、総合問題演習に取り組んでもらいます。今までに習ったデータサイエンスに関する色々な手法（データの読み込み、加工、機械学習のモデリング、検証など）が身に付いているかどうか確認するために、ぜひ取り組んでみてください。\n",
    "\n",
    "ゴール：問題解決に必要な手法を探し当て、適切に使用することができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf323c6-4195-11ea-86a9-02420a01000c",
     "next": "9bf3248e-4195-11ea-86a9-02420a01000c",
     "previous": "9bf322f4-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "- **[11.1 総合演習問題（1）](#11.1-総合演習問題（1）)**\n",
    "<br><br>\n",
    "- **[11.2 総合演習問題（2）](#11.2-総合演習問題（2）)**\n",
    "<br><br>\n",
    "- **[11.3 総合演習問題（3）](#11.3-総合演習問題（3）)**\n",
    "<br><br>\n",
    "- **[11.4 総合演習問題（4）](#11.4-総合演習問題（4）)**\n",
    "<br><br>\n",
    "- **[11.5 総合演習問題（5）](#11.5-総合演習問題（5）)**\n",
    "<br><br>\n",
    "- **[11.6 総合演習問題（6）](#11.6-総合演習問題（6）)**\n",
    "<br><br>\n",
    "- **[11.7 参考：今後のデータ分析に向けて](#11.7-参考：今後のデータ分析に向けて)**\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf3248e-4195-11ea-86a9-02420a01000c",
     "next": "9bf3254c-4195-11ea-86a9-02420a01000c",
     "previous": "9bf323c6-4195-11ea-86a9-02420a01000c"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 以下は必要なライブラリのため、あらかじめ読み込んでおいてください。\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import scipy as sp\n",
    "from pandas import Series,DataFrame\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# 可視化ライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# 機械学習ライブラリ\n",
    "import sklearn\n",
    "\n",
    "# 小数第３位まで表示\n",
    "%precision 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf3254c-4195-11ea-86a9-02420a01000c",
     "next": "9bf3260a-4195-11ea-86a9-02420a01000c",
     "previous": "9bf3248e-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "## 11.1 総合演習問題（1）\n",
    "キーワード：教師あり学習、画像認識、複数カテゴリーの分類、混同行列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf3260a-4195-11ea-86a9-02420a01000c",
     "next": "9bf326c8-4195-11ea-86a9-02420a01000c",
     "previous": "9bf3254c-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "Scikit-learnの`sklearn.datasets`パッケージに入っている手書き数字のデータセットを下記のように読み込み、各数字（0〜9）を予測するモデルを構築しましょう。このデータは、手書きの数字で、0から9までの画像データです。以下の実装では、データを読み込み、サンプルとなる数字の画像データを表示しています。\n",
    " \n",
    "数字のラベル（目的変数）が`digits.target`で、そのデータの特徴量（説明変数）は`digits.data`です。ここで、このデータをテストデータと学習データに分けてモデルを構築し、混同行列の結果を表示させてください。その際、何度実行しても同じように分離されるように`train_test_split`のパラメータで`random_state=0`と設定してください。\n",
    "\n",
    "また、いくつかモデルを作成し、比較してみてください。どのモデルを使いますか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf326c8-4195-11ea-86a9-02420a01000c",
     "next": "9bf32786-4195-11ea-86a9-02420a01000c",
     "previous": "9bf3260a-4195-11ea-86a9-02420a01000c"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 分析対象データ\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "# 画像の表示\n",
    "plt.figure(figsize=(20,5))\n",
    "for label, img in zip(digits.target[:10], digits.images[:10]):\n",
    "    plt.subplot(1,10,label+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img,cmap=plt.cm.gray_r,interpolation='nearest')\n",
    "    plt.title('Number:{0}'.format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf32786-4195-11ea-86a9-02420a01000c",
     "next": "9bf32844-4195-11ea-86a9-02420a01000c",
     "previous": "9bf326c8-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "## 11.2 総合演習問題（2）\n",
    "キーワード：教師あり学習、回帰、複数モデルの比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf32844-4195-11ea-86a9-02420a01000c",
     "next": "9bf32902-4195-11ea-86a9-02420a01000c",
     "previous": "9bf32786-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "以下のデータを読み込み、アワビの年齢を予測するモデルを構築してみましょう。目的変数は、「`Rings`」になります。 英語ですが参考URL「B-26」に参考情報を挙げてあります。\n",
    "\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf32902-4195-11ea-86a9-02420a01000c",
     "next": "9bf329c0-4195-11ea-86a9-02420a01000c",
     "previous": "9bf32844-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "## 11.3 総合演習問題（3）\n",
    "キーワード：教師あり学習、分類、マーケティング分析、検証、混同行列、正解率、適合率、再現率、F1スコア、ROC曲線、AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf329c0-4195-11ea-86a9-02420a01000c",
     "next": "9bf32a74-4195-11ea-86a9-02420a01000c",
     "previous": "9bf32902-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "9章で扱った、以下の金融機関のデータ（bank-full.csv）を読み込んで、後の問いに答えてください。\n",
    "\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf32a74-4195-11ea-86a9-02420a01000c",
     "next": "9bf32b32-4195-11ea-86a9-02420a01000c",
     "previous": "9bf329c0-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "1.  数値データ（`age,balance,day,duration,campaign,pdays,previous`）における基本統計量（レコード数、最大値、最小値、標準偏差など）を算出してください。  \n",
    "2.  データの`\"job\",\"marital\",\"education\",\"default\",\"housing\",\"loan\"`のそれぞれについて、預金を申し込む人、申し込まない人の人数を算出してください。　　\n",
    "3.   `y`（預金を申し込む、申し込まない）を目的変数として、予測モデルを構築してください。モデルは複数（ロジスティック回帰、SVM、決定木、k-NN、ランダムフォレストなど）を試してください。ただし、テスト用にデータはあらかじめ抜いてください（その際、`train_test_split`のパラメータは`random_state=0`で設定してください）。そして、それぞれのモデルの検証をしましょう。各モデルのテストデータにおける正解率、適合率、再現率、F1スコア、混同行列を表示してください。どのモデルを使いますか。  \n",
    "4.   3で選択したモデルについてROC曲線を描いて、AUCを算出し、比較できるようにしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf32b32-4195-11ea-86a9-02420a01000c",
     "next": "9bf32be6-4195-11ea-86a9-02420a01000c",
     "previous": "9bf32a74-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "## 11.4 総合演習問題（4）\n",
    "キーワード：教師あり学習、教師なし学習、ハイブリッドアプローチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf32be6-4195-11ea-86a9-02420a01000c",
     "next": "9bf32c9a-4195-11ea-86a9-02420a01000c",
     "previous": "9bf32b32-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "8章で扱ったload_breast_cancerを使って、さらに予測精度（正解率）を上げるモデルを作成してみましょう。テスト用にデータはあらかじめ抜いて検証してください。その際、`train_test_split`のパラメータを`random_state=0`に設定してください。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf32c9a-4195-11ea-86a9-02420a01000c",
     "next": "9bf32d58-4195-11ea-86a9-02420a01000c",
     "previous": "9bf32be6-4195-11ea-86a9-02420a01000c"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 前回の解答\n",
    "# 標準化のためのモジュール\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ロジスティック回帰\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, stratify = cancer.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf32d58-4195-11ea-86a9-02420a01000c",
     "next": "9bf32e16-4195-11ea-86a9-02420a01000c",
     "previous": "9bf32c9a-4195-11ea-86a9-02420a01000c"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 標準化\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf32e16-4195-11ea-86a9-02420a01000c",
     "next": "9bf32eca-4195-11ea-86a9-02420a01000c",
     "previous": "9bf32d58-4195-11ea-86a9-02420a01000c"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = LogisticRegression()\n",
    "clf = model.fit(X_train_std,y_train)\n",
    "print('train:',clf.__class__.__name__ ,clf.score(X_train_std,y_train))\n",
    "print('test:',clf.__class__.__name__ , clf.score(X_test_std,y_test))\n",
    "\n",
    "pred_y = clf.predict(X_test_std)\n",
    "confusion_m = confusion_matrix(y_test,pred_y)\n",
    "\n",
    "print('Confution matrix:\\n{}'.format(confusion_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf32eca-4195-11ea-86a9-02420a01000c",
     "next": "9bf32f88-4195-11ea-86a9-02420a01000c",
     "previous": "9bf32e16-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "データを標準化して、単純にモデルを当てはめるとテストデータで正解率95.8％でした。この結果を上回る方法を考えてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf32f88-4195-11ea-86a9-02420a01000c",
     "next": "9bf3303c-4195-11ea-86a9-02420a01000c",
     "previous": "9bf32eca-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "## 11.5 総合演習問題（5）\n",
    "キーワード：時系列データ、欠損データの補完、シフト、ヒストグラム、教師あり学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf3303c-4195-11ea-86a9-02420a01000c",
     "next": "9bf330fa-4195-11ea-86a9-02420a01000c",
     "previous": "9bf32f88-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "以下のように、2001年1月2日から2016年12月30日までの為替データ（ドル/円レートのJPYUSDとユーロ/ドルレートのUSDEUR）を読み込み、問いに答えてください。なお、DEXJPUSとDEXUSEUがそれぞれJPYUSDとUSDEURに想定しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf330fa-4195-11ea-86a9-02420a01000c",
     "next": "9bf331b8-4195-11ea-86a9-02420a01000c",
     "previous": "9bf3303c-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "1. 読み込んだデータには、祝日や休日等による欠損（NaN）があります。その補完処理をするために、直近の前の日におけるデータで補完してください。ただし年月のデータがない場合もありますので、その場合、今回は無視してください（改めて日付データを作成して、分析をすることも可能ですが、今回はこのアプローチはとりません。）。  \n",
    "2. 上記のデータで、各統計量の確認と時系列のグラフ化をしてください。  \n",
    "3. 当日と前日における差分をとり、それぞれの変化率（当日-前日）/前日のデータをヒストグラムで表示してください。　　  \n",
    "4. 将来の価格（例：次の日）を予測するモデルを構築してみましょう。具体的には、2016年11月を訓練データとして、当日の価格を目的変数として、前日、前々日、3日前の価格データを使ってモデル（線形回帰）を構築し、2016年12月をテストデータとして、検証してください。また、他の月や年で実施すると、どんな結果になりますか。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf331b8-4195-11ea-86a9-02420a01000c",
     "next": "9bf3326c-4195-11ea-86a9-02420a01000c",
     "previous": "9bf330fa-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "まず、以下を実行して、データをダウンロードしてください。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf3326c-4195-11ea-86a9-02420a01000c",
     "next": "9bf3332a-4195-11ea-86a9-02420a01000c",
     "previous": "9bf331b8-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "以下で、対象となる期間の為替データを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf3332a-4195-11ea-86a9-02420a01000c",
     "next": "9bf333e8-4195-11ea-86a9-02420a01000c",
     "previous": "9bf3326c-4195-11ea-86a9-02420a01000c"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas_datareader.data as pdr\n",
    "\n",
    "start_date = \"2001-01-02\"\n",
    "end_date = \"2016-12-30\"\n",
    "\n",
    "fx_jpusdata = pdr.DataReader(\"DEXJPUS\",\"fred\",start_date,end_date)\n",
    "fx_useudata = pdr.DataReader(\"DEXUSEU\",\"fred\",start_date,end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf333e8-4195-11ea-86a9-02420a01000c",
     "next": "9bf334a6-4195-11ea-86a9-02420a01000c",
     "previous": "9bf3332a-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "## 11.6 総合演習問題（6）\n",
    "キーワード：時系列データ、回帰分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf334a6-4195-11ea-86a9-02420a01000c",
     "next": "9bf33564-4195-11ea-86a9-02420a01000c",
     "previous": "9bf333e8-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "以下の米国の旅客飛行機のフライトデータ」を取得し、読み込んで以下の問いに答えてください。ただし、今回は2000年より前のデータ（1987～1999）を分析対象とします。\n",
    "\n",
    "http://stat-computing.org/dataexpo/2009/the-data.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf33564-4195-11ea-86a9-02420a01000c",
     "next": "9bf33622-4195-11ea-86a9-02420a01000c",
     "previous": "9bf334a6-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "\n",
    "\n",
    "データの取得は、以下のスクリプトを参考に、実装と実行をしてください。なお、シェルスクリプトはLinuxやMacの環境の方のみで、Windowsの方はその下のようなスクリプトで圧縮ファイルをダウンロードして解凍してください。**なお、データのダウンロードにとても時間がかかりますので、注意しましょう。**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf33622-4195-11ea-86a9-02420a01000c",
     "next": "9bf336e0-4195-11ea-86a9-02420a01000c",
     "previous": "9bf33564-4195-11ea-86a9-02420a01000c"
    }
   },
   "outputs": [],
   "source": [
    "#ダウンロードシェルスクリプト（Linux＆Mac）：\n",
    "\n",
    "#!/bin/sh\n",
    "\n",
    "for year in {1987..1999} ; do  \n",
    "    echo ¥$year  \n",
    "    wget http://stat-computing.org/dataexpo/2009/${year}.csv.bz2  \n",
    "    bzip2 -d ${year}.csv.bz2  \n",
    "done  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf336e0-4195-11ea-86a9-02420a01000c",
     "next": "9bf3379e-4195-11ea-86a9-02420a01000c",
     "previous": "9bf33622-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "シェルスクリプトを実行する場合は別ファイルとして、「ファイル名.sh」の形式で保存し、実行する場合は、「bash ファイル名.sh」で実行します。もしくは、ターミナルを使って専用のディレクトリなどを作って、スクリプトを実行して、データを取得してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf3379e-4195-11ea-86a9-02420a01000c",
     "next": "9bf3385c-4195-11ea-86a9-02420a01000c",
     "previous": "9bf336e0-4195-11ea-86a9-02420a01000c"
    }
   },
   "outputs": [],
   "source": [
    "#Pythonでダウンロード（Windows）：\n",
    "import urllib.request\n",
    "\n",
    "for year in range(1987,2000):    \n",
    "    url = 'http://stat-computing.org/dataexpo/2009/'\n",
    "    savename = str(year) + '.csv.bz2'\n",
    "    #ダウンロード \n",
    "    urllib.request.urlretrieve(url, savename)\n",
    "    print('{}年のファイルを保存しました'.format(year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf3385c-4195-11ea-86a9-02420a01000c",
     "next": "9bf3391a-4195-11ea-86a9-02420a01000c",
     "previous": "9bf3379e-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "1. データを読み込んだ後は、年（Year）×月（Month）の平均遅延時間（DepDelay）を算出してください。何かわかることはありますか。  \n",
    "2. 1で算出したデータについて、1月から12月までの結果を時系列の折れ線グラフにしてください。その時、年ごとに比較できるように、1つのグラフにまとめてください。ですので、1987年から1989年までのデータについて、それぞれの時系列グラフが並ぶイメージです。\n",
    "3. 各航空会社（UniqueCarrier）ごとの平均遅延時間を算出してください。また、出発地（Origin）、目的地（Dest）を軸にして、平均遅延時間を算出してください。  \n",
    "4. 遅延時間を予測するための予測モデルを構築します。目的変数をDepDelay、説明変数をArrDelayとDistanceにして、モデルを構築しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf3391a-4195-11ea-86a9-02420a01000c",
     "next": "9bf339ce-4195-11ea-86a9-02420a01000c",
     "previous": "9bf3385c-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "## 11.7 参考：今後のデータ分析に向けて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf339ce-4195-11ea-86a9-02420a01000c",
     "next": "9bf33a8c-4195-11ea-86a9-02420a01000c",
     "previous": "9bf3391a-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "以下は参考ですが、次のようなオープンデータを使って、データ分析に取り組んでみましょう。課題は明確になっていませんが、その課題を見つけることもデータ分析では大事です。\n",
    "\n",
    "1. どのデータを分析対象にしますか？また、どんなことを目的にデータを分析しますか？どんなことをゴールにしますか？    \n",
    "2. 分析対象となるデータに何か特徴や傾向はありますか？簡易集計してみましょう。そこからどんな仮設を立てますか？  \n",
    "3. 目的や仮説等が明確になったら、どんな風にアプローチしますか？実装して、検証してください。  \n",
    "4. 分析に明るくない人たち（中学校までの数学しかわからないと想定）に今回の分析結果を報告するとして、どのような報告書（グラフやインサイトなど含む）を作成しますか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf33a8c-4195-11ea-86a9-02420a01000c",
     "next": "9bf33b4a-4195-11ea-86a9-02420a01000c",
     "previous": "9bf339ce-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "なお、課題を特定していくことの重要性については、参考書籍「A-35」も参考になりますので、興味のある方は読んでみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf33b4a-4195-11ea-86a9-02420a01000c",
     "next": "9bf33d0c-4195-11ea-86a9-02420a01000c",
     "previous": "9bf33a8c-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "##### データソースサンプル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf33d0c-4195-11ea-86a9-02420a01000c",
     "next": "9bf33dfc-4195-11ea-86a9-02420a01000c",
     "previous": "9bf33b4a-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "- UCI DATA\n",
    "\n",
    "http://archive.ics.uci.edu/ml/\n",
    "\n",
    "- Bay Area Bike Share\n",
    "\n",
    "http://www.bayareabikeshare.com/open-data\n",
    "　　\n",
    "- movielens\n",
    "\n",
    "http://grouplens.org/datasets/movielens/\n",
    "\n",
    "\n",
    "- MLDATA\n",
    "\n",
    "http://mldata.org/\n",
    "\n",
    "- Churn Data Set（provided by IBM）\n",
    "\n",
    "https://community.watsonanalytics.com/wp-content/uploads/2015/03/WA_Fn-UseC_-Telco-Customer-Churn.csv\n",
    "\n",
    "- Netflix Prize Data Set　　\n",
    "\n",
    "http://academictorrents.com/details/9b13183dc4d60676b773c9e2cd6de5e5542cee9a　　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "9bf33dfc-4195-11ea-86a9-02420a01000c",
     "next": null,
     "previous": "9bf33d0c-4195-11ea-86a9-02420a01000c"
    }
   },
   "source": [
    "上記のほかにも、Kaggleなどのデータサイエンスのコンテストなどがありますので、スキルを上げていきたい方はチャレンジしてみてください。課題を提出するまでにいたらなくとも、Discussionなどで色々な人が自分たちの手法やアプローチを紹介したりしていますので、データ分析を学ぶ上でとても参考になります。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "lc_notebook_meme": {
   "current": "9bf31f16-4195-11ea-86a9-02420a01000c",
   "lc_server_signature": {
    "current": {
     "notebook_dir": "/home/yoko69d621",
     "notebook_path": "/tokyo-u-data-science/ds_samplefiles",
     "server_url": "https://nb03.ecloud.nii.ac.jp/user/yoko69d621/",
     "signature_id": "5e786c6e-5fea-11e9-b810-02420a00005a"
    },
    "history": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
